{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KPI Matrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the .txt file with '|' as the delimiter\n",
    "data = pd.read_csv('../assets/data/MachineLearningRating_v3.txt', delimiter='|')\n",
    "\n",
    "# Adding calculated columns for metrics\n",
    "data['ClaimFrequency'] = data['TotalClaims'] / data['TotalPremium']\n",
    "data['LossRatio'] = data['TotalClaims'] / data['TotalPremium']\n",
    "\n",
    "# 1. Risk differences across provinces\n",
    "province_kpis = data.groupby('Province').agg(\n",
    "    avg_claim_frequency=('ClaimFrequency', 'mean'),\n",
    "    avg_loss_ratio=('LossRatio', 'mean'),\n",
    "    total_claims=('TotalClaims', 'sum'),\n",
    "    total_premium=('TotalPremium', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "print(\"Risk KPIs by Province:\")\n",
    "print(province_kpis)\n",
    "\n",
    "# 2. Risk differences between zip codes\n",
    "zip_code_kpis = data.groupby('PostalCode').agg(\n",
    "    avg_claim_frequency=('ClaimFrequency', 'mean'),\n",
    "    avg_loss_ratio=('LossRatio', 'mean'),\n",
    "    total_claims=('TotalClaims', 'sum'),\n",
    "    total_premium=('TotalPremium', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "print(\"\\nRisk KPIs by Zip Code:\")\n",
    "print(zip_code_kpis)\n",
    "\n",
    "# 3. Margin differences between zip codes\n",
    "zip_code_margin_kpis = data.groupby('PostalCode').agg(\n",
    "    total_premium=('TotalPremium', 'sum'),\n",
    "    total_claims=('TotalClaims', 'sum')\n",
    ").reset_index()\n",
    "zip_code_margin_kpis['gross_margin_percentage'] = (\n",
    "    (zip_code_margin_kpis['total_premium'] - zip_code_margin_kpis['total_claims'])\n",
    "    / zip_code_margin_kpis['total_premium'] * 100\n",
    ")\n",
    "\n",
    "print(\"\\nMargin KPIs by Zip Code:\")\n",
    "print(zip_code_margin_kpis)\n",
    "\n",
    "# 4. Risk differences between Women and Men\n",
    "gender_kpis = data.groupby('Gender').agg(\n",
    "    avg_claim_frequency=('ClaimFrequency', 'mean'),\n",
    "    avg_loss_ratio=('LossRatio', 'mean'),\n",
    "    total_claims=('TotalClaims', 'sum'),\n",
    "    total_premium=('TotalPremium', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "print(\"\\nRisk KPIs by Gender:\")\n",
    "print(gender_kpis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for risk differences across provinces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_38099/1146143774.py:12: DtypeWarning: Columns (32,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('../assets/data/MachineLearningRating_v3.txt', delimiter='|')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Risk KPIs by Province:\n",
      "  Group       Province  avg_claim_frequency  avg_loss_ratio  total_claims  \\\n",
      "0     B   Eastern Cape                  inf             inf  1.356427e+06   \n",
      "1     B     Free State                  inf             inf  3.549223e+05   \n",
      "2     B        Gauteng                  NaN             NaN  2.939415e+07   \n",
      "3     B  KwaZulu-Natal                  inf             inf  1.430138e+07   \n",
      "4     B        Limpopo                  inf             inf  1.016477e+06   \n",
      "5     B     Mpumalanga                  NaN             NaN  2.044675e+06   \n",
      "6     B     North West                  inf             inf  5.920250e+06   \n",
      "7     B  Northern Cape             0.203831        0.203831  8.949051e+04   \n",
      "8     B   Western Cape                  inf             inf  1.038977e+07   \n",
      "\n",
      "   total_premium  \n",
      "0   2.140104e+06  \n",
      "1   5.213632e+05  \n",
      "2   2.405377e+07  \n",
      "3   1.320908e+07  \n",
      "4   1.537324e+06  \n",
      "5   2.836292e+06  \n",
      "6   7.490508e+06  \n",
      "7   3.165581e+05  \n",
      "8   9.806559e+06  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('../scripts')\n",
    "\n",
    "from KPI_segment import calculate_kpis\n",
    "\n",
    "\n",
    "\n",
    "# Example usage in the notebook\n",
    "\n",
    "# Load your dataset (since you already load it in the notebook)\n",
    "data = pd.read_csv('../assets/data/MachineLearningRating_v3.txt', delimiter='|')\n",
    "\n",
    "# Add calculated columns for risk metrics\n",
    "data['ClaimFrequency'] = data['TotalClaims'] / data['TotalPremium']\n",
    "data['LossRatio'] = data['TotalClaims'] / data['TotalPremium']\n",
    "\n",
    "# Set the segmentation feature\n",
    "segmentation_feature = 'Province'  # Replace with your segmentation feature\n",
    "\n",
    "# Call the function to calculate KPIs\n",
    "kpi_results = calculate_kpis(data, segmentation_feature)\n",
    "\n",
    "# Print the results\n",
    "print(\"\\nRisk KPIs by Province:\")\n",
    "print(kpi_results['province_kpis'])\n",
    "\n",
    "#save the dataset\n",
    "output_file = '../assets/data/segmented_kpis_by_province.csv'\n",
    "kpi_results['province_kpis'].to_csv(output_file, index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for risk differences between zip codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_38099/4191838247.py:12: DtypeWarning: Columns (32,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('../assets/data/MachineLearningRating_v3.txt', delimiter='|')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Risk KPIs by Zip Code:\n",
      "    Group  PostalCode  avg_claim_frequency  avg_loss_ratio   total_claims  \\\n",
      "0       B           1                  inf             inf  307583.342105   \n",
      "1       B           2             0.852758        0.852758   61885.298246   \n",
      "2       B           4             0.000000        0.000000       0.000000   \n",
      "3       B           5             0.698901        0.698901   82951.526316   \n",
      "4       B           6             0.122927        0.122927    8628.596491   \n",
      "..    ...         ...                  ...             ...            ...   \n",
      "883     B        9781                  inf             inf   89698.245614   \n",
      "884     B        9830             0.000000        0.000000       0.000000   \n",
      "885     B        9868             0.000000        0.000000       0.000000   \n",
      "886     B        9869             0.120710        0.120710    2236.842105   \n",
      "887     B        9870             0.000000        0.000000       0.000000   \n",
      "\n",
      "     total_premium  \n",
      "0    273035.326595  \n",
      "1     60861.729133  \n",
      "2      8773.975714  \n",
      "3     24661.450526  \n",
      "4     22260.230088  \n",
      "..             ...  \n",
      "883   35077.787598  \n",
      "884    7378.610100  \n",
      "885   11604.237719  \n",
      "886   63355.830081  \n",
      "887   17703.244175  \n",
      "\n",
      "[888 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import pandas as pd  # Ensure pandas is imported\n",
    "\n",
    "# Add the path to the 'scripts' folder if it's not already in the Python path\n",
    "sys.path.append('../scripts')\n",
    "\n",
    "# Import the function from KPI_segment.py\n",
    "from KPI_segment import calculate_kpis\n",
    "\n",
    "# Example usage in the notebook\n",
    "data = pd.read_csv('../assets/data/MachineLearningRating_v3.txt', delimiter='|')\n",
    "\n",
    "# Add calculated columns for risk metrics\n",
    "data['ClaimFrequency'] = data['TotalClaims'] / data['TotalPremium']\n",
    "data['LossRatio'] = data['TotalClaims'] / data['TotalPremium']\n",
    "\n",
    "# Insert the feature for segmentation manually in the notebook\n",
    "segmentation_feature = 'PostalCode'  # Insert your specific feature here\n",
    "\n",
    "# Call the function to calculate KPIs\n",
    "kpi_results = calculate_kpis(data, segmentation_feature)\n",
    "\n",
    "# Print the results\n",
    "print(\"\\nRisk KPIs by Zip Code:\")\n",
    "print(kpi_results['zip_code_kpis'])\n",
    "\n",
    "#save the dataset\n",
    "output_file = '../assets/data/segmented_kpis_by_zip_code.csv'\n",
    "kpi_results['zip_code_kpis'].to_csv(output_file, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for Margin differences between zip codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_38099/1010092588.py:11: DtypeWarning: Columns (32,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('../assets/data/MachineLearningRating_v3.txt', delimiter='|')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Margin KPIs by Zip Code:\n",
      "    Group  PostalCode  total_premium   total_claims  gross_margin_percentage\n",
      "0       B           1  273035.326595  307583.342105               -12.653313\n",
      "1       B           2   60861.729133   61885.298246                -1.681794\n",
      "2       B           4    8773.975714       0.000000               100.000000\n",
      "3       B           5   24661.450526   82951.526316              -236.361100\n",
      "4       B           6   22260.230088    8628.596491                61.237613\n",
      "..    ...         ...            ...            ...                      ...\n",
      "883     B        9781   35077.787598   89698.245614              -155.712380\n",
      "884     B        9830    7378.610100       0.000000               100.000000\n",
      "885     B        9868   11604.237719       0.000000               100.000000\n",
      "886     B        9869   63355.830081    2236.842105                96.469398\n",
      "887     B        9870   17703.244175       0.000000               100.000000\n",
      "\n",
      "[888 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd  # Ensure pandas is imported\n",
    "\n",
    "# Add the path to the 'scripts' folder if it's not already in the Python path\n",
    "sys.path.append('../scripts')\n",
    "\n",
    "# Import the function from KPI_segment.py\n",
    "from KPI_segment import calculate_kpis\n",
    "\n",
    "# Example usage in the notebook\n",
    "data = pd.read_csv('../assets/data/MachineLearningRating_v3.txt', delimiter='|')\n",
    "\n",
    "# Add calculated columns for risk metrics\n",
    "data['ClaimFrequency'] = data['TotalClaims'] / data['TotalPremium']\n",
    "data['LossRatio'] = data['TotalClaims'] / data['TotalPremium']\n",
    "\n",
    "# Insert the feature for segmentation manually in the notebook\n",
    "segmentation_feature = 'PostalCode'  # Insert your specific feature here\n",
    "\n",
    "# Call the function to calculate KPIs\n",
    "kpi_results = calculate_kpis(data, segmentation_feature)\n",
    "\n",
    "# Print the results\n",
    "print(\"\\nMargin KPIs by Zip Code:\")\n",
    "print(kpi_results['zip_code_margin_kpis'])\n",
    "#save the dataset\n",
    "output_file = '../assets/data/segmented_kpis_by_margin_zip_code.csv'\n",
    "kpi_results['zip_code_margin_kpis'].to_csv(output_file, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for risk differences between Women and Men"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_38099/85975619.py:11: DtypeWarning: Columns (32,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('../assets/data/MachineLearningRating_v3.txt', delimiter='|')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Risk KPIs by Gender:\n",
      "  Group         Gender  avg_claim_frequency  avg_loss_ratio  total_claims  \\\n",
      "0     B         Female                  inf             inf  2.502461e+05   \n",
      "1     B           Male                  inf             inf  1.396704e+06   \n",
      "2     B  Not specified                  NaN             NaN  6.271410e+07   \n",
      "\n",
      "   total_premium  \n",
      "0   3.044806e+05  \n",
      "1   1.580143e+06  \n",
      "2   5.920275e+07  \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd  # Ensure pandas is imported\n",
    "\n",
    "# Add the path to the 'scripts' folder if it's not already in the Python path\n",
    "sys.path.append('../scripts')\n",
    "\n",
    "# Import the function from KPI_segment.py\n",
    "from KPI_segment import calculate_kpis\n",
    "\n",
    "# Example usage in the notebook\n",
    "data = pd.read_csv('../assets/data/MachineLearningRating_v3.txt', delimiter='|')\n",
    "\n",
    "# Add calculated columns for risk metrics\n",
    "data['ClaimFrequency'] = data['TotalClaims'] / data['TotalPremium']\n",
    "data['LossRatio'] = data['TotalClaims'] / data['TotalPremium']\n",
    "\n",
    "# Insert the feature for segmentation manually in the notebook\n",
    "segmentation_feature = 'Gender'  # Insert your specific feature here\n",
    "\n",
    "# Call the function to calculate KPIs\n",
    "kpi_results = calculate_kpis(data, segmentation_feature)\n",
    "\n",
    "# Print the results\n",
    "print(\"\\nRisk KPIs by Gender:\")\n",
    "print(kpi_results['gender_kpis'])\n",
    "\n",
    "#save the dataset\n",
    "output_file = '../assets/data/segmented_kpis_by_gender.csv'\n",
    "kpi_results['gender_kpis'].to_csv(output_file, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value for avg_claim_frequency: nan\n",
      "Interpretation: Fail to reject null hypothesis: No significant impact\n",
      "\n",
      "p-value for avg_loss_ratio: nan\n",
      "Interpretation: Fail to reject null hypothesis: No significant impact\n",
      "\n",
      "p-value for total_claims: nan\n",
      "Interpretation: Fail to reject null hypothesis: No significant impact\n",
      "\n",
      "p-value for total_premium: nan\n",
      "Interpretation: Fail to reject null hypothesis: No significant impact\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_38099/731339939.py:20: SmallSampleWarning: One or more sample arguments is too small; all returned values will be NaN. See documentation for sample size requirements.\n",
      "  t_stat, p_val = stats.ttest_ind(control_values, test_values)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Gender'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/KAIM/week 3/task3/AlphaCare-insurance-solutions-/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Gender'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 94\u001b[0m\n\u001b[1;32m     91\u001b[0m gender_kpis \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../assets/data/segmented_kpis_by_gender.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# Call the main function to perform statistical tests\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprovince_kpis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzip_code_kpis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzip_code_margin_kpis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgender_kpis\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[26], line 67\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(province_kpis, zip_code_kpis, zip_code_margin_kpis, gender_kpis)\u001b[0m\n\u001b[1;32m     65\u001b[0m categorical_columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGender\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPostalCode\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Add other categorical KPIs\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m categorical_columns:\n\u001b[0;32m---> 67\u001b[0m     p_value \u001b[38;5;241m=\u001b[39m \u001b[43mchi_squared_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontrol_group\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_group\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mp-value for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterpretation: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minterpret_p_value(p_value)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[26], line 36\u001b[0m, in \u001b[0;36mchi_squared_test\u001b[0;34m(control_group, test_group, column)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;03mPerform a Chi-squared test for independence between two categorical variables.\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03m- p-value from the Chi-squared test.\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Create contingency table\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m contingency_table \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mcrosstab(\u001b[43mcontrol_group\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m]\u001b[49m, test_group[column])\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Perform Chi-squared test\u001b[39;00m\n\u001b[1;32m     39\u001b[0m chi2_stat, p_val, dof, expected \u001b[38;5;241m=\u001b[39m chi2_contingency(contingency_table)\n",
      "File \u001b[0;32m~/Desktop/KAIM/week 3/task3/AlphaCare-insurance-solutions-/.venv/lib/python3.10/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Desktop/KAIM/week 3/task3/AlphaCare-insurance-solutions-/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Gender'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "def t_test_kpis(control_group, test_group, column):\n",
    "    \"\"\"\n",
    "    Conduct a t-test between the Control and Test groups for a given KPI.\n",
    "    \n",
    "    Parameters:\n",
    "    - control_group: DataFrame for the control group.\n",
    "    - test_group: DataFrame for the test group.\n",
    "    - column: The column (KPI) to test.\n",
    "    \n",
    "    Returns:\n",
    "    - p-value from the t-test.\n",
    "    \"\"\"\n",
    "    control_values = control_group[column].dropna()  # Remove NaN values\n",
    "    test_values = test_group[column].dropna()  # Remove NaN values\n",
    "    \n",
    "    t_stat, p_val = stats.ttest_ind(control_values, test_values)\n",
    "    return p_val\n",
    "\n",
    "def chi_squared_test(control_group, test_group, column):\n",
    "    \"\"\"\n",
    "    Perform a Chi-squared test for independence between two categorical variables.\n",
    "    \n",
    "    Parameters:\n",
    "    - control_group: DataFrame for the control group.\n",
    "    - test_group: DataFrame for the test group.\n",
    "    - column: The categorical column to test (e.g., 'Gender').\n",
    "    \n",
    "    Returns:\n",
    "    - p-value from the Chi-squared test.\n",
    "    \"\"\"\n",
    "    # Create contingency table\n",
    "    contingency_table = pd.crosstab(control_group[column], test_group[column])\n",
    "    \n",
    "    # Perform Chi-squared test\n",
    "    chi2_stat, p_val, dof, expected = chi2_contingency(contingency_table)\n",
    "    return p_val\n",
    "\n",
    "def interpret_p_value(p_value):\n",
    "    \n",
    "    if p_value < 0.05:\n",
    "        return \"Reject null hypothesis: Significant impact\"\n",
    "    else:\n",
    "        return \"Fail to reject null hypothesis: No significant impact\"\n",
    "\n",
    "# Main function to run the statistical testing\n",
    "def main(province_kpis, zip_code_kpis, zip_code_margin_kpis, gender_kpis):\n",
    "    # Segment data into control and test groups\n",
    "    control_group = province_kpis[province_kpis['Group'] == 'A']\n",
    "    test_group = province_kpis[province_kpis['Group'] == 'B']\n",
    "\n",
    "    # Perform statistical tests for KPIs (numerical and categorical)\n",
    "    \n",
    "    # For numerical columns, perform t-test (e.g., avg_claim_frequency, avg_loss_ratio)\n",
    "    numerical_columns = ['avg_claim_frequency', 'avg_loss_ratio', 'total_claims', 'total_premium']  # Add other numerical KPIs\n",
    "    for col in numerical_columns:\n",
    "        p_value = t_test_kpis(control_group, test_group, col)\n",
    "        print(f\"p-value for {col}: {p_value}\")\n",
    "        print(f\"Interpretation: {interpret_p_value(p_value)}\\n\")\n",
    "\n",
    "    # For categorical columns, perform Chi-Squared test (e.g., Gender, PostalCode)\n",
    "    categorical_columns = ['Gender', 'PostalCode']  # Add other categorical KPIs\n",
    "    for col in categorical_columns:\n",
    "        p_value = chi_squared_test(control_group, test_group, col)\n",
    "        print(f\"p-value for {col}: {p_value}\")\n",
    "        print(f\"Interpretation: {interpret_p_value(p_value)}\\n\")\n",
    "    \n",
    "    # Optionally, print the KPIs for review\n",
    "    print(\"\\nRisk KPIs by Province:\")\n",
    "    print(province_kpis)\n",
    "\n",
    "    print(\"\\nRisk KPIs by Zip Code:\")\n",
    "    print(zip_code_kpis)\n",
    "\n",
    "    print(\"\\nMargin KPIs by Zip Code:\")\n",
    "    print(zip_code_margin_kpis)\n",
    "\n",
    "    print(\"\\nRisk KPIs by Gender:\")\n",
    "    print(gender_kpis)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == '__main__':\n",
    "    # Assuming the following DataFrames already contain your KPI results\n",
    "    # Replace these with the actual KPI DataFrames you have computed\n",
    "    province_kpis = pd.read_csv('../assets/data/segmented_kpis_by_province.csv')\n",
    "    zip_code_kpis = pd.read_csv('../assets/data/segmented_kpis_by_zip_code.csv')\n",
    "    zip_code_margin_kpis = pd.read_csv('../assets/data/segmented_kpis_by_margin_zip_code.csv')\n",
    "    gender_kpis = pd.read_csv('../assets/data/segmented_kpis_by_gender.csv')\n",
    "\n",
    "    # Call the main function to perform statistical tests\n",
    "    main(province_kpis, zip_code_kpis, zip_code_margin_kpis, gender_kpis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
