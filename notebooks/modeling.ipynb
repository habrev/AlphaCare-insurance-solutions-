{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5405/1201793596.py:5: DtypeWarning: Columns (32,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('../assets/data/MachineLearningRating_v3.txt', delimiter= '|')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing data per column:\n",
      "UnderwrittenCoverID               0\n",
      "PolicyID                          0\n",
      "TransactionMonth                  0\n",
      "IsVATRegistered                   0\n",
      "Citizenship                       0\n",
      "LegalType                         0\n",
      "Title                             0\n",
      "Language                          0\n",
      "Bank                         145961\n",
      "AccountType                   40232\n",
      "MaritalStatus                  8259\n",
      "Gender                         9536\n",
      "Country                           0\n",
      "Province                          0\n",
      "PostalCode                        0\n",
      "MainCrestaZone                    0\n",
      "SubCrestaZone                     0\n",
      "ItemType                          0\n",
      "mmcode                          552\n",
      "VehicleType                     552\n",
      "RegistrationYear                  0\n",
      "make                            552\n",
      "Model                           552\n",
      "Cylinders                       552\n",
      "cubiccapacity                   552\n",
      "kilowatts                       552\n",
      "bodytype                        552\n",
      "NumberOfDoors                   552\n",
      "VehicleIntroDate                552\n",
      "CustomValueEstimate          779642\n",
      "AlarmImmobiliser                  0\n",
      "TrackingDevice                    0\n",
      "CapitalOutstanding                2\n",
      "NewVehicle                   153295\n",
      "WrittenOff                   641901\n",
      "Rebuilt                      641901\n",
      "Converted                    641901\n",
      "CrossBorder                  999400\n",
      "NumberOfVehiclesInFleet     1000098\n",
      "SumInsured                        0\n",
      "TermFrequency                     0\n",
      "CalculatedPremiumPerTerm          0\n",
      "ExcessSelected                    0\n",
      "CoverCategory                     0\n",
      "CoverType                         0\n",
      "CoverGroup                        0\n",
      "Section                           0\n",
      "Product                           0\n",
      "StatutoryClass                    0\n",
      "StatutoryRiskType                 0\n",
      "TotalPremium                      0\n",
      "TotalClaims                       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load your data\n",
    "data = pd.read_csv('../assets/data/MachineLearningRating_v3.txt', delimiter= '|')\n",
    "\n",
    "# Check for missing data\n",
    "missing_data = data.isnull().sum()\n",
    "print(f\"Missing data per column:\\n{missing_data}\")\n",
    "\n",
    "# Define a threshold for removing columns with too many missing values (e.g., more than 50%)\n",
    "threshold = 0.5\n",
    "columns_to_remove = missing_data[missing_data / len(data) > threshold].index\n",
    "data_cleaned = data.drop(columns=columns_to_remove)\n",
    "\n",
    "# For columns with less missing data, handle them differently:\n",
    "# Impute numerical columns with the mean\n",
    "numerical_columns = data_cleaned.select_dtypes(include=['float64', 'int64']).columns\n",
    "numerical_imputer = SimpleImputer(strategy='mean')\n",
    "data_cleaned[numerical_columns] = numerical_imputer.fit_transform(data_cleaned[numerical_columns])\n",
    "\n",
    "# Impute categorical columns with the most frequent value (mode)\n",
    "categorical_columns = data_cleaned.select_dtypes(include=['object']).columns\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "data_cleaned[categorical_columns] = categorical_imputer.fit_transform(data_cleaned[categorical_columns])\n",
    "\n",
    "# Optional: Save the cleaned data\n",
    "data_cleaned.to_csv('../assets/data/cleaned_dataset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5122/1477367607.py:3: DtypeWarning: Columns (32,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('../assets/data/MachineLearningRating_v3.txt', delimiter= '|')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ClaimFrequency  LossRatio  ClaimsToPremiumDiff\n",
      "0                   0.0        0.0            21.929825\n",
      "1                   0.0        0.0            21.929825\n",
      "2                   0.0        0.0             0.000000\n",
      "3                   0.0        0.0           512.848070\n",
      "4                   0.0        0.0             0.000000\n",
      "...                 ...        ...                  ...\n",
      "1000093             0.0        0.0           347.235175\n",
      "1000094             0.0        0.0           347.235175\n",
      "1000095             0.0        0.0           347.235175\n",
      "1000096             0.0        0.0             2.315000\n",
      "1000097             0.0        0.0             2.315000\n",
      "\n",
      "[1000098 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load your data\n",
    "data = pd.read_csv('../assets/data/MachineLearningRating_v3.txt', delimiter= '|')\n",
    "# Create new features\n",
    "data['ClaimFrequency'] = data['TotalClaims'] / (data['TotalPremium'] + 1)  # Added 1 to avoid division by zero\n",
    "data['LossRatio'] = data['TotalClaims'] / (data['TotalPremium'] + 1)  # Added 1 for safety\n",
    "data['ClaimsToPremiumDiff'] = data['TotalPremium'] - data['TotalClaims']\n",
    "# Display the new features\n",
    "print(data[['ClaimFrequency', 'LossRatio', 'ClaimsToPremiumDiff']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding categorical column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5867/913296397.py:4: DtypeWarning: Columns (32,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('../assets/data/MachineLearningRating_v3.txt', delimiter= '|')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset:\n",
      "   UnderwrittenCoverID  PolicyID     TransactionMonth  IsVATRegistered  \\\n",
      "0               145249     12827  2015-03-01 00:00:00             True   \n",
      "1               145249     12827  2015-05-01 00:00:00             True   \n",
      "2               145249     12827  2015-07-01 00:00:00             True   \n",
      "3               145255     12827  2015-05-01 00:00:00             True   \n",
      "4               145255     12827  2015-07-01 00:00:00             True   \n",
      "\n",
      "  Citizenship          LegalType Title Language                 Bank  \\\n",
      "0              Close Corporation    Mr  English  First National Bank   \n",
      "1              Close Corporation    Mr  English  First National Bank   \n",
      "2              Close Corporation    Mr  English  First National Bank   \n",
      "3              Close Corporation    Mr  English  First National Bank   \n",
      "4              Close Corporation    Mr  English  First National Bank   \n",
      "\n",
      "       AccountType  ...                    ExcessSelected CoverCategory  \\\n",
      "0  Current account  ...             Mobility - Windscreen    Windscreen   \n",
      "1  Current account  ...             Mobility - Windscreen    Windscreen   \n",
      "2  Current account  ...             Mobility - Windscreen    Windscreen   \n",
      "3  Current account  ...  Mobility - Metered Taxis - R2000    Own damage   \n",
      "4  Current account  ...  Mobility - Metered Taxis - R2000    Own damage   \n",
      "\n",
      "    CoverType            CoverGroup              Section  \\\n",
      "0  Windscreen  Comprehensive - Taxi  Motor Comprehensive   \n",
      "1  Windscreen  Comprehensive - Taxi  Motor Comprehensive   \n",
      "2  Windscreen  Comprehensive - Taxi  Motor Comprehensive   \n",
      "3  Own Damage  Comprehensive - Taxi  Motor Comprehensive   \n",
      "4  Own Damage  Comprehensive - Taxi  Motor Comprehensive   \n",
      "\n",
      "                           Product StatutoryClass StatutoryRiskType  \\\n",
      "0  Mobility Metered Taxis: Monthly     Commercial     IFRS Constant   \n",
      "1  Mobility Metered Taxis: Monthly     Commercial     IFRS Constant   \n",
      "2  Mobility Metered Taxis: Monthly     Commercial     IFRS Constant   \n",
      "3  Mobility Metered Taxis: Monthly     Commercial     IFRS Constant   \n",
      "4  Mobility Metered Taxis: Monthly     Commercial     IFRS Constant   \n",
      "\n",
      "   TotalPremium TotalClaims  \n",
      "0     21.929825         0.0  \n",
      "1     21.929825         0.0  \n",
      "2      0.000000         0.0  \n",
      "3    512.848070         0.0  \n",
      "4      0.000000         0.0  \n",
      "\n",
      "[5 rows x 52 columns]\n",
      "\n",
      "Categorical Columns: Index(['TransactionMonth', 'Citizenship', 'LegalType', 'Title', 'Language',\n",
      "       'Bank', 'AccountType', 'MaritalStatus', 'Gender', 'Country', 'Province',\n",
      "       'MainCrestaZone', 'SubCrestaZone', 'ItemType', 'VehicleType', 'make',\n",
      "       'Model', 'bodytype', 'VehicleIntroDate', 'AlarmImmobiliser',\n",
      "       'TrackingDevice', 'CapitalOutstanding', 'NewVehicle', 'WrittenOff',\n",
      "       'Rebuilt', 'Converted', 'CrossBorder', 'TermFrequency',\n",
      "       'ExcessSelected', 'CoverCategory', 'CoverType', 'CoverGroup', 'Section',\n",
      "       'Product', 'StatutoryClass', 'StatutoryRiskType'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.read_csv('../assets/data/MachineLearningRating_v3.txt', delimiter= '|')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(\"Original Dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# Step 2: Identify categorical columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "print(\"\\nCategorical Columns:\", categorical_cols)\n",
    "\n",
    "# Step 3: Apply One-Hot Encoding\n",
    "df_one_hot = pd.get_dummies(df, columns=categorical_cols)\n",
    "\n",
    "# Save the one-hot encoded dataset to a new file (optional)\n",
    "df_one_hot.to_csv(\"../assets/data/dataset_one_hot_encoded.csv\", index=False)\n",
    "\n",
    "print(\"\\nOne-Hot Encoded Dataset:\")\n",
    "print(df_one_hot.head())\n",
    "\n",
    "# Step 4: Apply Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Create a copy of the dataset for label encoding\n",
    "df_label_encoded = df.copy()\n",
    "\n",
    "# Apply label encoding to each categorical column\n",
    "for col in categorical_cols:\n",
    "    df_label_encoded[col + \"_encoded\"] = label_encoder.fit_transform(df_label_encoded[col])\n",
    "\n",
    "# Save the label encoded dataset to a new file (optional)\n",
    "df_label_encoded.to_csv(\"../assets/data/dataset_label_encoded.csv\", index=False)\n",
    "\n",
    "print(\"\\nLabel Encoded Dataset:\")\n",
    "print(df_label_encoded.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Splitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"path/to/your/dataset.csv\"  # Replace with your actual file path\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Perform the train-test split\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Save the train and test sets (optional)\n",
    "train_data.to_csv(\"train_data.csv\", index=False)\n",
    "test_data.to_csv(\"test_data.csv\", index=False)\n",
    "\n",
    "print(\"Train and test sets created successfully!\")\n",
    "print(f\"Training set size: {len(train_data)}\")\n",
    "print(f\"Test set size: {len(test_data)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
